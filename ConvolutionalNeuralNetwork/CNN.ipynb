{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "D9_LCWTqrSsn",
        "outputId": "161d5e17-ce73-4cc2-8eab-02e3c29d4665"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nNICOLE JOSEPH\\nDeep Learning HW 3\\n'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "NICOLE JOSEPH\n",
        "Deep Learning HW 3\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "BHmdqdT1_uCS"
      },
      "outputs": [],
      "source": [
        "# citation: To load the MNIST data \n",
        "# https://colab.research.google.com/github/AviatorMoser/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb#scrollTo=oYLlg52B_uCJ\n",
        "\n",
        "# Function to download the MNIST dataset - avoid using built in keras MNIST dataset\n",
        "from requests import get\n",
        "def download_file(url, file_name):\n",
        "    with open(file_name, \"wb\") as file:\n",
        "        response = get(url)\n",
        "        file.write(response.content)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "l-X6Te7vscYQ"
      },
      "outputs": [],
      "source": [
        "# MNIST data set downloaded from http://yann.lecun.com/exdb/mnist/\n",
        "download_file('http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz', 'train-images-idx3-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz', 't10k-images-idx3-ubyte.gz')\n",
        "download_file('http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz', 't10k-labels-idx1-ubyte.gz')\n",
        "\n",
        "# print(\"files downloaded\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d75tK_2NE5hK",
        "outputId": "0e1d6451-4564-444b-9a9e-12c627ef378f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: seaborn==0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.9.0) (1.7.3)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.9.0) (1.3.5)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.9.0) (1.21.6)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.7/dist-packages (from seaborn==0.9.0) (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.3->seaborn==0.9.0) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn==0.9.0) (4.1.1)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.15.2->seaborn==0.9.0) (2022.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.3->seaborn==0.9.0) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install seaborn==0.9.0\n",
        "!pip install --upgrade scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "Q54KwJWlFAEP"
      },
      "outputs": [],
      "source": [
        "import gzip\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Dropout, Activation # Types of layers to be used in the model\n",
        "from keras.models import Sequential  # Model type to be used\n",
        "from tensorflow.python.keras import regularizers\n",
        "\n",
        "from keras.utils import np_utils                       \n",
        "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, GlobalAveragePooling2D, Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "EIxEYG-iFhJ5"
      },
      "outputs": [],
      "source": [
        "# Data Set Understanding:\n",
        "# training set images: 60,000 28x28 pixel images for training\n",
        "# training set labels: 60,000 corresponding labels for training\n",
        "# test set images: 10,000 28x28 pixel images for testing\n",
        "# test set labels: 10,000 corresponding labels for testing\n",
        "\n",
        "def read_mnist(images_path: str, labels_path: str):\n",
        "    with gzip.open(labels_path, 'rb') as labelsFile:\n",
        "        labels = np.frombuffer(labelsFile.read(), dtype=np.uint8, offset=8)\n",
        "        # don't need to reshape labels\n",
        "\n",
        "    with gzip.open(images_path,'rb') as imagesFile:\n",
        "        length = len(labels)\n",
        "        # Load flat 28x28 px images (784 px), and convert them to 28x28 px\n",
        "        features = np.frombuffer(imagesFile.read(), dtype=np.uint8, offset=16) \\\n",
        "                        .reshape(length, 784) \\\n",
        "                        .reshape(length, 28, 28, 1)\n",
        "        \n",
        "    return features, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "57jIe6wAM1xH"
      },
      "outputs": [],
      "source": [
        "# citation: https://colab.research.google.com/github/AviatorMoser/keras-mnist-tutorial/blob/master/MNIST%20in%20Keras.ipynb#scrollTo=e1PU9ymwIaOj\n",
        "# we don't need to flatten each image into a 784-length vector because we want to perform convolutions first\n",
        "# add an additional dimension to represent the single-channel\n",
        "\n",
        "# Expected shapes:\n",
        "#X_train\n",
        "# (60000, 28, 28, 1)\n",
        "#y_train\n",
        "# (60000,) ONE DIMENSIONAL ARRAY\n",
        "# X_test\n",
        "# (10000, 28, 28, 1)\n",
        "# y_test\n",
        "# (10000,)\n",
        "\n",
        "# initialize multi-dimensional arrays by providing shape\n",
        "X_train = np.empty(shape=(60000, 28, 28, 1), dtype='object')\n",
        "y_train = np.empty(shape=(60000,), dtype='object')\n",
        "X_test = np.empty(shape=(10000, 28, 28, 1), dtype='object')\n",
        "y_test = np.empty(shape=(10000,), dtype='object')\n",
        "\n",
        "X_train, y_train = read_mnist('train-images-idx3-ubyte.gz', 'train-labels-idx1-ubyte.gz')\n",
        "X_test, y_test = read_mnist('t10k-images-idx3-ubyte.gz', 't10k-labels-idx1-ubyte.gz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "KxbXSDJPM5T1"
      },
      "outputs": [],
      "source": [
        "# verify that read_mnist function call worked\n",
        "#print(X_train[5:8, 7:10 ])\n",
        "#print (y_test[20:25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "id": "bk4GfWVHM-Ty"
      },
      "outputs": [],
      "source": [
        "# Preparing pixel data\n",
        "# Pixel values for each image in the dataset are unsigned integers in the range between black and white, or 0 and 255\n",
        "# Normalize the pixel values of grayscale images (rescale them to the range [0,1] )\n",
        "\n",
        "# convert integers to 32-bit floating point numbers\n",
        "X_train = X_train.astype('float32')         \n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# then divide the pixel values by the maximum value in order to normalize\n",
        "X_train = X_train/255                              \n",
        "X_test = X_test/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "Y7L0_MrZXZn5"
      },
      "outputs": [],
      "source": [
        "# one-hot encoding for classes/labels\n",
        "# number of unique digits\n",
        "nb_classes = 10 \n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
        "Y_test = np_utils.to_categorical(y_test, nb_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "vlOkPLaOcFTg"
      },
      "outputs": [],
      "source": [
        "# For CNN model architecture, this resource below was very helpful:\n",
        "# citation: https://colab.research.google.com/github/slxu/CSE548-Course-Project/blob/master/mnist_keras.ipynb#scrollTo=4IXmdGQSlPz1 \n",
        "\n",
        "#Linear stacking of layers\n",
        "model = Sequential()\n",
        "\n",
        "# For implementing L2 Regularization:\n",
        "# citation: https://colab.research.google.com/github/dphi-official/Deep_Learning_Bootcamp/blob/master/Optimization_Techniques/Regularization_and_Dropout.ipynb#scrollTo=s4afU-2YsDQg\n",
        "# kernel_regularizer is a parameter of Dense\n",
        "\n",
        "# Convolution Layer 1\n",
        "# 32 different 3x3 kernels --> 32 feature maps\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1), kernel_regularizer=regularizers.l2(l2=0.01))) \n",
        "# normalize each feature map before activation\n",
        "model.add(BatchNormalization(axis=-1))    \n",
        "# activation           \n",
        "convLayer01 = Activation('relu')                     \n",
        "model.add(convLayer01)\n",
        "\n",
        "# Convolution Layer 2\n",
        "model.add(Conv2D(32, (3, 3), kernel_regularizer=regularizers.l2(l2=0.2)))     \n",
        "model.add(BatchNormalization(axis=-1))               \n",
        "model.add(Activation('relu')) \n",
        "# Pool the max values over a 2x2 kernel                       \n",
        "convLayer02 = MaxPooling2D(pool_size=(2,2))          \n",
        "model.add(convLayer02)\n",
        "\n",
        "# Convolution Layer 3\n",
        "# 64 different 3x3 kernels --> so 64 feature maps\n",
        "model.add(Conv2D(64,(3, 3), kernel_regularizer=regularizers.l2(l2=0.01)))      \n",
        "model.add(BatchNormalization(axis=-1))               \n",
        "convLayer03 = Activation('relu')                     \n",
        "model.add(convLayer03)\n",
        "\n",
        "# Convolution Layer 4\n",
        "model.add(Conv2D(64, (3, 3), kernel_regularizer=regularizers.l2(l2=0.01)))     \n",
        "model.add(BatchNormalization(axis=-1))               \n",
        "model.add(Activation('relu'))\n",
        "# Pool the max values over a 2x2 kernel                        \n",
        "convLayer04 = MaxPooling2D(pool_size=(2,2))          \n",
        "model.add(convLayer04)\n",
        "# Flatten final 4x4x64 output matrix into a 1024-length vector\n",
        "model.add(Flatten())                                 \n",
        "\n",
        "# Fully Connected Layer 5\n",
        "# 512 FCN nodes\n",
        "model.add(Dense(512, kernel_regularizer = regularizers.l2(l2=0.01)))              \n",
        "model.add(BatchNormalization())                      \n",
        "model.add(Activation('relu'))                        \n",
        "\n",
        "# Fully Connected Layer 6\n",
        "# 20% dropout of randomly selected nodes                       \n",
        "model.add(Dropout(0.2))\n",
        "# final 10 FCN nodes                              \n",
        "model.add(Dense(10, kernel_regularizer = regularizers.l2(l2=0.01)))\n",
        "# softmax activation for output layer           \n",
        "model.add(Activation('softmax'))                     \n",
        "\n",
        "# compile model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='SGD', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6vRuMKzcGMe",
        "outputId": "f4184aad-2085-4da4-db14-6f21d67dec38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_107 (Conv2D)         (None, 26, 26, 32)        320       \n",
            "                                                                 \n",
            " batch_normalization_120 (Ba  (None, 26, 26, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_133 (Activation)  (None, 26, 26, 32)       0         \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 24, 24, 32)        9248      \n",
            "                                                                 \n",
            " batch_normalization_121 (Ba  (None, 24, 24, 32)       128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_134 (Activation)  (None, 24, 24, 32)       0         \n",
            "                                                                 \n",
            " max_pooling2d_50 (MaxPoolin  (None, 12, 12, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 10, 10, 64)        18496     \n",
            "                                                                 \n",
            " batch_normalization_122 (Ba  (None, 10, 10, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_135 (Activation)  (None, 10, 10, 64)       0         \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 8, 8, 64)          36928     \n",
            "                                                                 \n",
            " batch_normalization_123 (Ba  (None, 8, 8, 64)         256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_136 (Activation)  (None, 8, 8, 64)         0         \n",
            "                                                                 \n",
            " max_pooling2d_51 (MaxPoolin  (None, 4, 4, 64)         0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_24 (Flatten)        (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 512)               524800    \n",
            "                                                                 \n",
            " batch_normalization_124 (Ba  (None, 512)              2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_137 (Activation)  (None, 512)              0         \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 512)               0         \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 10)                5130      \n",
            "                                                                 \n",
            " activation_138 (Activation)  (None, 10)               0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 597,738\n",
            "Trainable params: 596,330\n",
            "Non-trainable params: 1,408\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6qEBv2FcF-Z",
        "outputId": "208bc87e-d467-4cf9-e5ea-39274c92cb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "375/375 [==============================] - 142s 378ms/step - loss: 3.6620 - accuracy: 0.9868 - val_loss: 3.4124 - val_accuracy: 0.9826\n",
            "Epoch 2/5\n",
            "375/375 [==============================] - 140s 373ms/step - loss: 3.1617 - accuracy: 0.9880 - val_loss: 2.9477 - val_accuracy: 0.9860\n",
            "Epoch 3/5\n",
            "375/375 [==============================] - 141s 377ms/step - loss: 2.7316 - accuracy: 0.9890 - val_loss: 2.5427 - val_accuracy: 0.9884\n",
            "Epoch 4/5\n",
            "375/375 [==============================] - 141s 375ms/step - loss: 2.3594 - accuracy: 0.9901 - val_loss: 2.1980 - val_accuracy: 0.9886\n",
            "Epoch 5/5\n",
            "375/375 [==============================] - 138s 369ms/step - loss: 2.0422 - accuracy: 0.9910 - val_loss: 1.8975 - val_accuracy: 0.9907\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0ef908dd90>"
            ]
          },
          "execution_count": 116,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# validation during training stage\n",
        "# citation: https://stackoverflow.com/questions/68428331/is-validation-split-0-2-in-keras-a-cross-validation\n",
        "# citation: https://datascience.stackexchange.com/questions/38955/how-does-the-validation-split-parameter-of-keras-fit-function-work\n",
        "\n",
        "#steps_per_epoch = # samples divided by batch size\n",
        "model.fit(X_train, Y_train, batch_size=128, epochs=5, verbose=1, validation_split=0.2, shuffle = True, steps_per_epoch=48000//128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "flkiF6pecGng",
        "outputId": "0fd2550f-2fd9-483c-9f68-ba9d1309b25c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 9s 28ms/step - loss: 1.8937 - accuracy: 0.9918\n",
            "Test score: 1.893710732460022\n",
            "Test accuracy: 0.9918000102043152\n"
          ]
        }
      ],
      "source": [
        "# citation: https://androidkt.com/what-does-model-evaluate-return-keras/\n",
        "score = model.evaluate(X_test, Y_test)\n",
        "#print(model.metrics_names)\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
